<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Explaining Credit Card Customers churns | Case Studies</title>
  <meta name="description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Explaining Credit Card Customers churns | Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Explaining Credit Card Customers churns | Case Studies" />
  
  <meta name="twitter:description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="" />


<meta name="date" content="2021-05-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="explainable-artificial-intelligence.html"/>
<link rel="next" href="explainable-artificial-inteligence-r.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>Case Studies</h3></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="technical-setup.html"><a href="technical-setup.html"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="explainable-artificial-intelligence.html"><a href="explainable-artificial-intelligence.html"><i class="fa fa-check"></i><b>1</b> Explainable Artificial Intelligence</a><ul>
<li class="chapter" data-level="1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html"><i class="fa fa-check"></i><b>1.1</b> Explaining Credit Card Customers churns</a><ul>
<li class="chapter" data-level="1.1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#global-explanations"><i class="fa fa-check"></i><b>1.1.1</b> Global explanations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="explainable-artificial-inteligence-r.html"><a href="explainable-artificial-inteligence-r.html"><i class="fa fa-check"></i><b>2</b> Explainable artificial inteligence (R)</a></li>
<li class="chapter" data-level="3" data-path="deep-learning-1.html"><a href="deep-learning-1.html"><i class="fa fa-check"></i><b>3</b> Deep Learning 1</a></li>
<li class="chapter" data-level="4" data-path="deep-learning-2.html"><a href="deep-learning-2.html"><i class="fa fa-check"></i><b>4</b> Deep Learning 2</a></li>
<li class="chapter" data-level="5" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>5</b> Machine Learning</a></li>
<li class="chapter" data-level="6" data-path="rashomonml.html"><a href="rashomonml.html"><i class="fa fa-check"></i><b>6</b> RashomonML</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="xai1-explainable-cards" class="section level2">
<h2><span class="header-section-number">1.1</span> Explaining Credit Card Customers churns</h2>
<p><em>Authors: Katarzyna Solawa, Przemys≈Çaw Chojecki, Bartosz Sawicki (Warsaw University of Technology)</em></p>
<div id="global-explanations" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Global explanations</h3>
<p>In this section we describe our discoveries made by using explenatory methods globally.</p>
<div id="permutational-feature-importance" class="section level4">
<h4><span class="header-section-number">1.1.1.1</span> Permutational Feature Importance</h4>
<p>We calculated permutational feature importance for XGBoost model, Random Forest model and a group of logistic regression models. The regression models were created with L1 regularization and different <code>C</code> coefficient was applied among the group. This coefficient is an inverse of a penalty term in L1 regularization, which means the smaller it is, the more weights shrinkage we expect. We examined if such shrinkage is noticeable in Permutational Feature Importance method. Then, we compared PFI obtained from different models.</p>
<div id="logistic-regression-models" class="section level5">
<h5><span class="header-section-number">1.1.1.1.1</span> Logistic Regression Models</h5>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-total-ct-chng"></span>
<img src="images/1-1-pfi-log-reg-group-total-ct-chng.png" alt="Permutational Feature Impotance of `Total_Ct_Chng_Q4_Q1` for the group of logistic regression models" width="700" />
<p class="caption">
FIGURE 1.1: Permutational Feature Impotance of <code>Total_Ct_Chng_Q4_Q1</code> for the group of logistic regression models
</p>
</div>
<p>The variable with the highest (among the group of logistic regressions) drop-out loss is shown in <a href="xai1-explainable-cards.html#fig:pfi-log-reg-total-ct-chng">1.1</a>. The drop-out increases with the increase of <code>C</code> coefficient. The feature is more important for models with low regularization parameter, therefore it was shrinked by the Lasso.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-total-bal"></span>
<img src="images/1-1-pfi-log-reg-group-total-revolving-bal.png" alt="Permutational Feature Impotance of `Total_Revolving_Bal` for the group of logistic regression models" width="700" />
<p class="caption">
FIGURE 1.2: Permutational Feature Impotance of <code>Total_Revolving_Bal</code> for the group of logistic regression models
</p>
</div>
<p><a href="xai1-explainable-cards.html#fig:pfi-log-reg-total-bal">1.2</a> presents a variable importance plot of <code>Total_Revolving_Bal</code> feature, which has the second highest drop-out loss. It was not regularized, because drop-out loss decreases with the increase of <code>C</code>. It is the only column, which has this property.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-gender"></span>
<img src="images/1-1-pfi-log-reg-group-gender.png" alt="Permutational Feature Impotance of `Gender` for the group of logistic regression models" width="700" />
<p class="caption">
FIGURE 1.3: Permutational Feature Impotance of <code>Gender</code> for the group of logistic regression models
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-utilization"></span>
<img src="images/1-1-pfi-log-reg-group-utilization.png" alt="Permutational Feature Impotance of `Avg_Utilization_Ratio` for the group of logistic regression models" width="700" />
<p class="caption">
FIGURE 1.4: Permutational Feature Impotance of <code>Avg_Utilization_Ratio</code> for the group of logistic regression models
</p>
</div>
<p>On the other plots, such as <a href="xai1-explainable-cards.html#fig:pfi-log-reg-gender">1.3</a> and <a href="xai1-explainable-cards.html#fig:pfi-log-reg-utilization">1.4</a>, the shrinkage made by L1 regularization is clearly visable. Models with high regularization parameter, and accordingly low <code>C</code> parameter, have smaller drop-out losses, which indicates lower importance of features.</p>
<p>Drop-out loss increases proportionally to <code>C</code> parameter in nearly all of 21 columns. This shows that the effects of Lasso regularization can be observed in variable importance plots of logistic regression models.</p>
</div>
<div id="xgboost-and-random-forest-models" class="section level5">
<h5><span class="header-section-number">1.1.1.1.2</span> XGBoost and Random Forest models</h5>
<p>In <a href="xai1-explainable-cards.html#fig:pfi-xgb-rf">1.5</a> we can observe that the most important column for both models is <code>Total_Trans_Amt</code>. This outcome can be logicall explained: customers who do not use their credit card to execute many valuable transactions probably do not need that service, consequently resign. However, drop-out loss is over 2 times higher in the XGBoost, which means that this model bases its prediction on this column more than Random Forest model does. Furthermore, more features are important for the XGBoost than for the Random Forest. We suppose this is a result of the models different training processes. New iterations (trees) in XGB are based on observations which were previously predicted incorrectly, thus new columns are taken into consideration to represent the differences between the observations. On the other hand, the Random Forest model selects the subset the features randomly in each individual tree.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-xgb-rf"></span>
<img src="images/1-1-permutational-feature-xgb-rf.png" alt="Top 9 most important features in XGBoost and RandomForest feature importance comparison" width="700" />
<p class="caption">
FIGURE 1.5: Top 9 most important features in XGBoost and RandomForest feature importance comparison
</p>
</div>
</div>
<div id="models-comparison" class="section level5">
<h5><span class="header-section-number">1.1.1.1.3</span> Models comparison</h5>
<p>We compared the permutational feature importance of the group of logistic regression models, XGBoost model and Random Forest model. We can see in <a href="xai1-explainable-cards.html#fig:pfi-all-total-trans">1.6</a> the drop-out loss in XGBoost is similar to drop-out in logistic regresison models.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-all-total-trans"></span>
<img src="images/1-1-pfi-all-models-total-trans-amt.png" alt="Permutational Feature Impotance of `Total_Trans_Amt` for all models" width="700" />
<p class="caption">
FIGURE 1.6: Permutational Feature Impotance of <code>Total_Trans_Amt</code> for all models
</p>
</div>
If we compare, however, the importance of <code>Total_Revolving_Bal</code> in <a href="xai1-explainable-cards.html#fig:pfi-all-total-bal">1.7</a>, we see huge difference between tree based models and regression models.The drop-out loss for the first ones around 20 times lower than for the latters.
<div class="figure" style="text-align: center"><span id="fig:pfi-all-total-bal"></span>
<img src="images/1-1-pfi-all-models-total-revolving-bal.png" alt="Permutational Feature Impotance of `Total_Revolving_Bal` for all models" width="700" />
<p class="caption">
FIGURE 1.7: Permutational Feature Impotance of <code>Total_Revolving_Bal</code> for all models
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pfi-all-gender"></span>
<img src="images/1-1-pfi-all-models-gender.png" alt="Permutational Feature Impotance of `Gender` for all models" width="700" />
<p class="caption">
FIGURE 1.8: Permutational Feature Impotance of <code>Gender</code> for all models
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pfi-all-utilization"></span>
<img src="images/1-1-pfi-all-models-utilization-ratio.png" alt="Permutational Feature Impotance of `Avg_Utilization_Ratio` for all models" width="700" />
<p class="caption">
FIGURE 1.9: Permutational Feature Impotance of <code>Avg_Utilization_Ratio</code> for all models
</p>
</div>
<p>We can also examine some of the less important features such as <code>Gender</code> (see <a href="xai1-explainable-cards.html#fig:pfi-all-gender">1.8</a> ) and <code>Avg_Utilization_Ratio</code> (see <a href="xai1-explainable-cards.html#fig:pfi-all-utilization">1.9</a>). In comparison to regression models importance of these variables in XGBoost and Random forest is neglectable. Therefore, we conclude that although the effects of L1 regularization in logistic regression are observable, tree-based models such as XGBoost and Random Forest can select the most important features more precisely.</p>
</div>
</div>
<div id="pdp-profiles" class="section level4">
<h4><span class="header-section-number">1.1.1.2</span> PDP profiles</h4>
<p>We created Partial Dependence Plots of all variables in the dataset for XGBoost, Random Forest and Logistic Regression with L1 models. Many of the plots turned out to be a horizontal line located on the level of the mean prediction of the models. An example of such a variable is shown in <a href="xai1-explainable-cards.html#fig:pdp-chosen">1.10</a>, predictions of models does not change with the change of <code>Gender</code>. However, features that have high importance do have more complex plots. One can observe prediction varying with the change of <code>Total_Trans_Amt</code>, <code>Total_Revolving_Bal</code> or <code>Total_Ct_Chng_Q4_Q1</code>.</p>
<div class="figure" style="text-align: center"><span id="fig:pdp-chosen"></span>
<img src="images/1-1-pdp-chosen-vars.png" alt="Partial Dependence Plots of chosen features" width="700" />
<p class="caption">
FIGURE 1.10: Partial Dependence Plots of chosen features
</p>
</div>
<p>What we find interesting in <a href="xai1-explainable-cards.html#fig:pdp-chosen">1.10</a> is an unobserved earlier effect of <code>Contacts_Count_12_mon</code> variable. The plot is steady for values 1-5 and raises rapidly when the feature takes value of 6. We examined this case and figured out, that only approx. 0.58% of all observations have value 6 in <code>Contacts_Count_12_mon</code> column. What is more, all of them describe attrited customers. We concluded there are two possilbe solutions:</p>
<ol style="list-style-type: decimal">
<li>The dataset is not balanced for this feature.</li>
<li>Indeed, the 6th contact with the bank representative is a breakthrough in the relationship with the customer.</li>
</ol>
</div>
<div id="ale-profiles" class="section level4">
<h4><span class="header-section-number">1.1.1.3</span> ALE profiles</h4>
<div class="figure" style="text-align: center"><span id="fig:ale-chosen"></span>
<img src="images/1-1-ale-chosen-vars.png" alt="Accumulated-local Profiles Plots of chosen features" width="700" />
<p class="caption">
FIGURE 1.11: Accumulated-local Profiles Plots of chosen features
</p>
</div>
<p>Accumulated-local Profiles for XGBoost, Random Forest and Logistic Regression with L1 were calcutated. The results for chosen variables are shown in <a href="xai1-explainable-cards.html#fig:ale-chosen">1.11</a>. ALE plots seem to be very similar to PDP profiles. It may suggest there are no interactions between variables in the models. To examine that we ploted both PDP and ALE profiles in <a href="xai1-explainable-cards.html#fig:ale-pdp-chosen-xgb">1.12</a>, <a href="xai1-explainable-cards.html#fig:ale-pdp-chosen-rf">1.13</a>. We skip this plots for Logistic Regression, because by definition there are no variables interactions in this class of models. ALE and PDP plots are pararell thus models detected no interactions between features and they are additive.</p>
<div class="figure" style="text-align: center"><span id="fig:ale-pdp-chosen-xgb"></span>
<img src="images/1-1-ale-pdp-xgb.png" alt="Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for XGBoost" width="700" />
<p class="caption">
FIGURE 1.12: Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for XGBoost
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ale-pdp-chosen-rf"></span>
<img src="images/1-1-ale-pdp-rf.png" alt="Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for Random Forest" width="700" />
<p class="caption">
FIGURE 1.13: Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for Random Forest
</p>
</div>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="explainable-artificial-intelligence.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="explainable-artificial-inteligence-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mini-pw/2021L-WB-Book/edit/master/1-1-creditCards.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
