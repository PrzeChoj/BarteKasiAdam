<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Explaining Credit Card Customers churns | Case Studies</title>
  <meta name="description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Explaining Credit Card Customers churns | Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Explaining Credit Card Customers churns | Case Studies" />
  
  <meta name="twitter:description" content="Case studies for explainable artificial intelligence, deep learning, machine learning." />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="" />


<meta name="date" content="2021-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="explainable-artificial-intelligence.html"/>
<link rel="next" href="explainable-artificial-inteligence-r.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>Case Studies</h3></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="technical-setup.html"><a href="technical-setup.html"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="explainable-artificial-intelligence.html"><a href="explainable-artificial-intelligence.html"><i class="fa fa-check"></i><b>1</b> Explainable Artificial Intelligence</a><ul>
<li class="chapter" data-level="1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html"><i class="fa fa-check"></i><b>1.1</b> Explaining Credit Card Customers churns</a><ul>
<li class="chapter" data-level="1.1.1" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#introduction-and-motivation"><i class="fa fa-check"></i><b>1.1.1</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.1.2" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#methodology"><i class="fa fa-check"></i><b>1.1.2</b> Methodology</a></li>
<li class="chapter" data-level="1.1.3" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#local-explanations"><i class="fa fa-check"></i><b>1.1.3</b> Local explanations</a></li>
<li class="chapter" data-level="1.1.4" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#global-explanations"><i class="fa fa-check"></i><b>1.1.4</b> Global explanations</a></li>
<li class="chapter" data-level="1.1.5" data-path="xai1-explainable-cards.html"><a href="xai1-explainable-cards.html#summary"><i class="fa fa-check"></i><b>1.1.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="explainable-artificial-inteligence-r.html"><a href="explainable-artificial-inteligence-r.html"><i class="fa fa-check"></i><b>2</b> Explainable artificial inteligence (R)</a></li>
<li class="chapter" data-level="3" data-path="deep-learning-1.html"><a href="deep-learning-1.html"><i class="fa fa-check"></i><b>3</b> Deep Learning 1</a></li>
<li class="chapter" data-level="4" data-path="deep-learning-2.html"><a href="deep-learning-2.html"><i class="fa fa-check"></i><b>4</b> Deep Learning 2</a></li>
<li class="chapter" data-level="5" data-path="machine-learning-1.html"><a href="machine-learning-1.html"><i class="fa fa-check"></i><b>5</b> Machine Learning</a></li>
<li class="chapter" data-level="6" data-path="rashomonml.html"><a href="rashomonml.html"><i class="fa fa-check"></i><b>6</b> RashomonML</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="xai1-explainable-cards" class="section level2">
<h2><span class="header-section-number">1.1</span> Explaining Credit Card Customers churns</h2>
<p><em>Authors: Katarzyna Solawa, Przemysław Chojecki, Bartosz Sawicki (Warsaw University of Technology)</em></p>
<div id="introduction-and-motivation" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Introduction and Motivation</h3>
<p>eXplainable Artificial Intelligence has become popular in recent years. Both the academia and buisness are interested in development in this field. Therefore, a lot of software packages enabling in-depth model analysis have been deployed. One of them is Dalex <span class="citation">(Baniecki et al. <a href="#ref-dalex">2020</a>)</span>. We will use this Python package to explain Credit Card Customers attrition. We will base our work on Credit Card customers <span class="citation">(Goyal <a href="#ref-1-1-credit-card-dataset">2020</a>)</span> dataset. Additionally to explaining factors that make customers churn, we want to compare black-box models and white-box model using XAI methods. We intend to examine if there is a trade-off between accuracy and explainability, how it is stated in <span class="citation">(Loyola-González <a href="#ref-1-1-white-box-black-box">2019</a>)</span>. We want to check if feature importance in L1 regularized Logistic Regression varies with a change in regularization strength. Similar study comparing feature importance measures was made <span class="citation">(Saarela and Jauhiainen <a href="#ref-1-1-l1-reg-random-forest">2021</a>)</span>. We extend that comparison and include XGBoost model.</p>
</div>
<div id="methodology" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Methodology</h3>
<div id="dataset" class="section level4">
<h4><span class="header-section-number">1.1.2.1</span> Dataset</h4>
<p>We will deliver our analysis on the data about resignation from using the credit card. The original collection contains information about 10 127 of the bank’s customers. The goal of this data was to predict whether the customer decides to discontinue using a credit card. This data set consists of 19 predictors:</p>
<ul>
<li><code>Customer_Age</code> - Customer’s Age in Years</li>
<li><code>Gender</code> - Gender of a Customer</li>
<li><code>Dependent_count</code> - Number of people dependant to a customer</li>
<li><code>Education_Level</code> - Educational qualification of the account holder</li>
<li><code>Marital_Status</code> - Customer’s Marital Status</li>
<li><code>Income_Category</code> - Customer’s Annual Income Category</li>
<li><code>Card_Category</code> - Type of Card (Blue, Silver, Gold, Platinum)</li>
<li><code>Months_on_book</code> - Number of months the account exists</li>
<li><code>Total_Relationship_Count</code> - Number of bank products held by the customer</li>
<li><code>Months_Inactive_12_mon</code> - Number of months with no transfers in the last 12 months</li>
<li><code>Contacts_Count_12_mon</code> - Number of times the account holder contacted the bank in the last 12 months (phone, mail, visit in facility)</li>
<li><code>Credit_Limit</code> - The maximum amount of credit that a Card owner can take</li>
<li><code>Total_Revolving_Bal</code> - Total amount of credit that a Card owner did not pay at the end of the billing cycle</li>
<li><code>Avg_Open_To_Buy</code> - Average of 12 months of the maximum possible amount of cash available to the account holder to spend</li>
<li><code>Total_Amt_Chng_Q4_Q1</code> - Change in Transaction Amount between last and first quarter of the year</li>
<li><code>Total_Trans_Amt</code> - Sum of all Transaction Amounts in last 12 months</li>
<li><code>Total_Trans_Ct</code> - Number of all Transaction Amounts in last 12 months</li>
<li><code>Total_Ct_Chng_Q4_Q1</code> - Change in number of Transactions between last and first quarter of the year</li>
<li><code>Avg_Utilization_Ratio</code> - Average use of possible credit in the last 12 months</li>
</ul>
<p>The target variable in the set is <code>Attrition_Flag</code>, which determines whether the customer did close its Credit Cards service. 16% of customers in Dataset decided to stop using their Cards. The other 84% will continue to be the bank’s customers.</p>
<div class="figure" style="text-align: center"><span id="fig:targetCounts"></span>
<img src="images/1-1-target-count.png" alt="Numbers of customers who decided to closed their Credit Cards service" width="700" />
<p class="caption">
FIGURE 1.1: Numbers of customers who decided to closed their Credit Cards service
</p>
</div>
<div id="data-preparation" class="section level5">
<h5><span class="header-section-number">1.1.2.1.1</span> Data preparation</h5>
<p>We have observed some of the columns had a giant correlation with others. Namely, <code>Months_on_book</code>, <code>Total_Trans_Ct</code> and <code>Credit_Limit</code> each had another column which it was correlated with (Pearson correlation over <span class="math inline">\(0.75\)</span>). That’s why we decided to drop those columns from models.</p>
<p>Some of the data had missing values. For every such case, we imputed the missing values with a median and made a new column informing whether there was a missing value or not.</p>
<p>For the categorial columns with order (like <code>Card_Category</code>: <em>Blue</em> &lt; <em>Silver</em> &lt; <em>Gold</em> &lt; <em>Platinum</em>) we encoded it with growing numbers.</p>
<p>For other categorical columns, we applied one-hot encoding.</p>
</div>
</div>
<div id="machine-learning" class="section level4">
<h4><span class="header-section-number">1.1.2.2</span> Machine learning</h4>
<p>To find the differences between tree-based models and a white-box these algorithms were selected:</p>
<ul>
<li><em>XGBoost</em></li>
<li><em>Random forest</em></li>
<li><em>Logistic Regression</em> with <em>L1</em> penalty</li>
</ul>
<p>The first two are commonly used, black-box, tree-based models. The last is a well known generalized linear model for classification.</p>
<p>Tree-based models tend to be overfitting. What is more, they tend to choose 4 or 5 columns to be deeply dependent on and almost completely ignore the rest. That is why the <em>Logistic Regression</em> analyzed in this article was modified with the <em>L1</em> penalty. This modification makes a model “select” some of the predictors to predict from and the rest is ignored. It is possible to adjust the strength of a penalty with a <em>C</em> parameter. The smaller the <em>C</em>, the fewer columns are selected to be proper predictors for a model. Number of Logistic Regression models were trained and the model with the highest accuracy score was selected to be described in all parts, except Permutational Feature Importance. In that part we use numerous Logistic Regression models with different regularization strenght.</p>
</div>
<div id="assumptions-of-logistic-regression" class="section level4">
<h4><span class="header-section-number">1.1.2.3</span> Assumptions of Logistic Regression</h4>
<p>A <em>Logistic Regression</em> model is derived from assumptions on data. Those assumptions can be summarised by a sentence: “Probability of being in a certain class is a logit function of a linear combination of predictors”. The exact assumption states:</p>
<p>A data has <span class="math inline">\(n\)</span> predictors. Let <span class="math inline">\(x\in \mathbb{R}^n\)</span> be a value of those predictors and <span class="math inline">\(p(x)\)</span> be a probalility that the target value is <span class="math inline">\(1\)</span> provided those values of predictors. Then there exist <span class="math inline">\(\beta_0\in\mathbb{R}\)</span> and <span class="math inline">\(\beta\in\mathbb{R}^n\)</span> that <span class="math display">\[\log(\frac{p(x)}{1-p(x)}) = \beta_0 + \sum_{i=1}^{n}(\beta_i \cdot x_i)\]</span></p>
<p>The <em>Logistic Regression</em> model finds the best fitting values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>In practice, this assumption states, that the best fitting line to the data shown in Figure <a href="xai1-explainable-cards.html#fig:LogReg-assumption">1.2</a> is well fitted and that the points arrange around it.</p>
<div class="figure" style="text-align: center"><span id="fig:LogReg-assumption"></span>
<img src="images/1-1-LogReg-assumption.png" alt="Figures showing the assumptions of Logistic Regression on some of the columns of the data" width="700" />
<p class="caption">
FIGURE 1.2: Figures showing the assumptions of Logistic Regression on some of the columns of the data
</p>
</div>
<p>Appropriate graphs of all of the variables can be examined on this article’s <a href="https://github.com/PrzeChoj/BarteKasiAdam">GitHub repository</a>. Those graphs look similar to the five shown in <a href="xai1-explainable-cards.html#fig:LogReg-assumption">1.2</a>, which are:</p>
<ul>
<li><code>Total_Ct_Chng_Q4_Q1</code> - satisfies the assumption;</li>
<li><code>Customer_Age</code> - looks like a data-blob;</li>
<li><code>Total_Trans_Amt</code> - provides a more complicated dependency than a straight line;</li>
<li><code>Marital_Married</code> - a binary column, therefore it is hard to conclude if it is well fitted or not;</li>
<li><code>Contacts_Count_12_mon</code> - multilabel discrete column, but rightly fitted.</li>
</ul>
<p>We concluded some of the columns may be slightly inappropriate to model linearly, but overall the Assumptions of <em>Logistic Regression</em> are mostly satisfied.</p>
</div>
<div id="methods-of-explainable-artificial-intelligence" class="section level4">
<h4><span class="header-section-number">1.1.2.4</span> Methods of Explainable Artificial Intelligence</h4>
<p>In the article, we used some Explainable Artificial Intelligence (XAI) methods to explain models. Those methods are:</p>
<ol style="list-style-type: decimal">
<li>Local methods:</li>
</ol>
<ul>
<li>Break Down</li>
<li>Shapley Values</li>
<li>Ceteris Paribus</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Global methods:</li>
</ol>
<ul>
<li>Permutational Feature Importance</li>
<li>Partial Dependence Profiles (PDP)</li>
<li>Accumulated Local Effects (ALE)</li>
</ul>
</div>
</div>
<div id="local-explanations" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Local explanations</h3>
<p>In this section we describe our discoveries made by using explanatory methods locally. For analysis were used three types of observations: misclassified, correctly classified and uncertainly classified.</p>
<div id="logistic-regression-model" class="section level4">
<h4><span class="header-section-number">1.1.3.1</span> Logistic Regression Model</h4>
<div id="misclassified" class="section level5">
<h5><span class="header-section-number">1.1.3.1.1</span> Misclassified</h5>
<p>The customer resigned, but the Logistic Regression (LR) model predicted his resignation only with a probability of 31%.</p>
<div class="figure" style="text-align: center"><span id="fig:log-reg-wrong-breakdown"></span>
<img src="images/1-1-log-reg-wrong-breakdown.png" alt="Break Down decomposition of obervation misclassified by LR model" width="700" />
<p class="caption">
FIGURE 1.3: Break Down decomposition of obervation misclassified by LR model
</p>
</div>
<p>According to Break Down, the variables <code>Total_Revolving_Bal</code> = 0 and <code>Total_Ct_Chng_Q4_Q1</code> = 0.5 had the greatest contribution to the correct prediction. This means that the client did not leave an unpaid overdraft and in the fourth quarter made two time less transactions as in the first.</p>
<div class="figure" style="text-align: center"><span id="fig:log-reg-wrong-cp"></span>
<img src="images/1-1-log-reg-wrong-cp.png" alt="Ceteris Paribus Profiles of obervation misclassified by LR model" width="700" />
<p class="caption">
FIGURE 1.4: Ceteris Paribus Profiles of obervation misclassified by LR model
</p>
</div>
<p>According to Ceteris Paribus, the biggest changes in prediction were caused by the variables <code>Total_Revolving_Bal</code>, <code>Total_Ct_Chng_Q4_Q1</code>, <code>Total_Relationship_Count</code>, <code>Contacts_Count_12_mon</code>, <code>Card_Category</code> and <code>Months_Inactive_12_mon</code>.</p>
</div>
<div id="correctly-classified" class="section level5">
<h5><span class="header-section-number">1.1.3.1.2</span> Correctly classified</h5>
The Logistic Regression model predicted that the client would drop out with a probability of almost 0%.
<div class="figure" style="text-align: center"><span id="fig:log-reg-good-shapley"></span>
<img src="images/1-1-log-reg-good-shapley.png" alt="Shapley Values decompositon of obervation correctly classified by LR model" width="700" />
<p class="caption">
FIGURE 1.5: Shapley Values decompositon of obervation correctly classified by LR model
</p>
</div>
<p>According to Shapley Values, the variable <code>Total_Ct_Chng_Q4_Q1</code> = 2.5 has the highest contribution. This means that the client carries out 2.5 times more transactions.</p>
<div class="figure" style="text-align: center"><span id="fig:log-reg-good-cp"></span>
<img src="images/1-1-log-reg-good-cp.png" alt="Ceteris Paribus Profiles of obervation correctly classified by LR model" width="700" />
<p class="caption">
FIGURE 1.6: Ceteris Paribus Profiles of obervation correctly classified by LR model
</p>
</div>
<p>The Ceteris Paribus profiles shows that this is the only variable that can change the prediction for this observation. To increase the churn prediction, <code>Total_Ct_Chng_Q4_Q1</code> would need to be less than 1.</p>
</div>
<div id="uncertain-classified" class="section level5">
<h5><span class="header-section-number">1.1.3.1.3</span> Uncertain classified</h5>
<p>The selected customer did not resign from the service, but the model prediction was uncertain with a result of 54%.</p>
<div class="figure" style="text-align: center"><span id="fig:log-reg-uc-breakdown"></span>
<img src="images/1-1-log-reg-uc-breakdown.png" alt="Break Down decomposition of obervation uncertain classified by LR model" width="700" />
<p class="caption">
FIGURE 1.7: Break Down decomposition of obervation uncertain classified by LR model
</p>
</div>
<p>According to Break Down variables of the largest contribution are <code>Total_Revolving_Bal</code> and <code>Total_Relationship_Count</code>. Customer has no unpaid loans at the end of the months, and have few relationships with a bank. There is no important sings of churn but at the same time there is no important sings of being interested in bank services, so it is hard for LR model to make correct prediction.</p>
<div class="figure" style="text-align: center"><span id="fig:log-reg-uc-cp"></span>
<img src="images/1-1-log-reg-uc-cp.png" alt="Ceteris Paribus Profiles of obervation uncertain classified by LR model" width="700" />
<p class="caption">
FIGURE 1.8: Ceteris Paribus Profiles of obervation uncertain classified by LR model
</p>
</div>
<p>Using Ceteris Paribus profiles, we can see that a slight change of one of the variables: <code>Total_Revolving_Bal</code>, <code>Total_Relationship_Count</code>, <code>Contacts_Count_12_mon</code>, <code>Months_Inactive_12_mon</code>, <code>Total_Trans_Amt</code> , <code>Total_Ct_Chng_Q4_Q1</code> is enough for the prediction to be more decisive.</p>
</div>
</div>
<div id="xgboost-and-random-forest-model" class="section level4">
<h4><span class="header-section-number">1.1.3.2</span> XGBoost and Random Forest model</h4>
<div id="misclassified-1" class="section level5">
<h5><span class="header-section-number">1.1.3.2.1</span> Misclassified</h5>
<p>The customer terminated the services, but both XGBoost and Random Forest got it wrong. They predicted chances of churn of 0.5% and 4%.</p>
<div class="figure" style="text-align: center"><span id="fig:xgb-wrong-shapley"></span>
<img src="images/1-1-xgb-wrong-shapley.png" alt="Shapley values decompositon of obervation misclassified classified by XGB and RF model" width="700" /><img src="images/1-1-rf-wrong-shapley.png" alt="Shapley values decompositon of obervation misclassified classified by XGB and RF model" width="700" />
<p class="caption">
FIGURE 1.9: Shapley values decompositon of obervation misclassified classified by XGB and RF model
</p>
</div>
<p>The <code>Total_Trans_Amt</code> column affects the result in the right direction, but its contribution is obscured by <code>Total_Revolving_Bal</code>, <code>Months_Inactive_12_mon</code>,<code>Total_Relationship_Count</code>, and <code>Contacts_Count_12_mon</code>.</p>
<div class="figure" style="text-align: center"><span id="fig:xgb-rf-wrong-cp"></span>
<img src="images/1-1-xgb-rf-wrong-cp.png" alt="Ceteris Paribus Profiles of obervation misclassified classified by XGB and RF model" width="700" />
<p class="caption">
FIGURE 1.10: Ceteris Paribus Profiles of obervation misclassified classified by XGB and RF model
</p>
</div>
<p>According to Ceteris Paribus, in order for the result of the models to agree with the label, one of the following events would have to occur:</p>
<ul>
<li><p><code>Contact_Count_12_mon</code> = 6</p></li>
<li><p><code>Total_Trans_Amt</code> &lt; 850</p></li>
</ul>
</div>
<div id="correctly-classified-1" class="section level5">
<h5><span class="header-section-number">1.1.3.2.2</span> Correctly classified</h5>
<p>The client continues to use the service, and both XGBoost and Random Forest were fully convinced that this would be the case (about 0% churn prediction).</p>
<div class="figure" style="text-align: center"><span id="fig:xgb-good-breakdown"></span>
<img src="images/1-1-XGB-good-breakdown.png" alt="Break Down decompositon of obervation correctly classified by XGB and RF model" width="700" /><img src="images/1-1-rf-good-breakdown.png" alt="Break Down decompositon of obervation correctly classified by XGB and RF model" width="700" />
<p class="caption">
FIGURE 1.11: Break Down decompositon of obervation correctly classified by XGB and RF model
</p>
</div>
<p>Looking at the Break Down , we suspect that due to <code>Total_Realtionship_Count</code> = 1 the bank is afraid that it is not holding the client tightly enough and that the client is considering leaving. Despite this, the models returned a good prediction caused by a large amount of money circulating in the customer’s account and large loans not repaid on time .</p>
</div>
<div id="uncertain-classified-1" class="section level5">
<h5><span class="header-section-number">1.1.3.2.3</span> Uncertain classified</h5>
The customer resigned from the service. Both models will slightly lean towards customer resignation (52-53%), but this is a very uncertain prediction.
<div class="figure" style="text-align: center"><span id="fig:xgb-uc-breakdown"></span>
<img src="images/1-1-XGB-uc-breakdown.png" alt="Break Down decompositon of obervation uncertain classified by XGB and RF model" width="700" /><img src="images/1-1-rf-uc-breakdown.png" alt="Break Down decompositon of obervation uncertain classified by XGB and RF model" width="700" />
<p class="caption">
FIGURE 1.12: Break Down decompositon of obervation uncertain classified by XGB and RF model
</p>
</div>
<p>Similar to the previous observations, the variables <code>Total_Revolving_Bal</code> and <code>Total_Trans_Amt</code> have the largest contribution.</p>
<div class="figure" style="text-align: center"><span id="fig:xgb-rf-uc-cp"></span>
<img src="images/1-1-xgb-rf-uc-cb.png" alt="Ceteris Paribus Profiles of obervation uncertain classified by XGB and RF model" width="700" />
<p class="caption">
FIGURE 1.13: Ceteris Paribus Profiles of obervation uncertain classified by XGB and RF model
</p>
</div>
<p>According to the Ceteris Paribus profiles, as for the LR observations, there are a few variables for which small changes can significantly improve the predictions.</p>
</div>
</div>
</div>
<div id="global-explanations" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Global explanations</h3>
<p>In this section we describe our discoveries made by using explenatory methods globally.</p>
<div id="permutational-feature-importance" class="section level4">
<h4><span class="header-section-number">1.1.4.1</span> Permutational Feature Importance</h4>
<p>We calculated Permutational Feature Importance for XGBoost model, Random Forest model and a group of Logistic Regression models. The Regression models were created with L1 regularization and different <code>C</code> coefficient was applied among the group. This coefficient is an inverse of a penalty term in L1 regularization, which means the smaller it is, the more weights shrinkage we expect. We examined if such shrinkage is noticeable in Permutational Feature Importance (PFI) method. Then, we compared PFI obtained from different models.</p>
<div id="logistic-regression-models" class="section level5">
<h5><span class="header-section-number">1.1.4.1.1</span> Logistic Regression Models</h5>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-total-ct-chng"></span>
<img src="images/1-1-pfi-log-reg-group-total-ct-chng.png" alt="Permutational Feature Impotance of `Total_Ct_Chng_Q4_Q1` for the group of Logistic Regression models. This variable represents the change in number of transactions between Quarter 4 and Quarter 1. Its importance decreases when L1 regularization incerases." width="700" />
<p class="caption">
FIGURE 1.14: Permutational Feature Impotance of <code>Total_Ct_Chng_Q4_Q1</code> for the group of Logistic Regression models. This variable represents the change in number of transactions between Quarter 4 and Quarter 1. Its importance decreases when L1 regularization incerases.
</p>
</div>
<p>The variable with the highest (among the group of Logistic Regressions) drop-out loss is shown in Figure <a href="xai1-explainable-cards.html#fig:pfi-log-reg-total-ct-chng">1.14</a>. The drop-out increases with the increase of <code>C</code> coefficient. The feature is more important for models with low regularization parameter, therefore it was shrinked by the Lasso.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-total-bal"></span>
<img src="images/1-1-pfi-log-reg-group-total-revolving-bal.png" alt="Permutational Feature Impotance of `Total_Revolving_Bal` for the group of Logistic Regression models. It is more important for models with high regularization." width="700" />
<p class="caption">
FIGURE 1.15: Permutational Feature Impotance of <code>Total_Revolving_Bal</code> for the group of Logistic Regression models. It is more important for models with high regularization.
</p>
</div>
<p>Figure <a href="xai1-explainable-cards.html#fig:pfi-log-reg-total-bal">1.15</a> presents a variable importance plot of <code>Total_Revolving_Bal</code> (Total amount of credit that a Card owner did not pay at the end of the billing cycle) feature, which has the second highest drop-out loss. It was not regularized, because drop-out loss decreases with the increase of <code>C</code>. It is the only column, which has this property.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-gender"></span>
<img src="images/1-1-pfi-log-reg-group-gender.png" alt="Permutational Feature Impotance of `Gender` (Gender of a Customer) for the group of Logistic Regression models. This variable was clearly regularized by L1 regresssion. Importance increases with a decrease of regularization strength." width="700" />
<p class="caption">
FIGURE 1.16: Permutational Feature Impotance of <code>Gender</code> (Gender of a Customer) for the group of Logistic Regression models. This variable was clearly regularized by L1 regresssion. Importance increases with a decrease of regularization strength.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pfi-log-reg-utilization"></span>
<img src="images/1-1-pfi-log-reg-group-utilization.png" alt="Permutational Feature Impotance of `Avg_Utilization_Ratio`, which stands for an average use of possible credit in the last 12 months, for the group of Logistic Regression models. The stronger regularization gets, the less importatn this variable is." width="700" />
<p class="caption">
FIGURE 1.17: Permutational Feature Impotance of <code>Avg_Utilization_Ratio</code>, which stands for an average use of possible credit in the last 12 months, for the group of Logistic Regression models. The stronger regularization gets, the less importatn this variable is.
</p>
</div>
<p>On the other plots, such as Figure <a href="xai1-explainable-cards.html#fig:pfi-log-reg-gender">1.16</a> and Figure <a href="xai1-explainable-cards.html#fig:pfi-log-reg-utilization">1.17</a>, the shrinkage made by L1 regularization is clearly visable. Models with high regularization parameter, and accordingly low <code>C</code> parameter, have smaller drop-out losses, which indicates lower importance of features.</p>
<p>Drop-out loss increases proportionally to <code>C</code> parameter in nearly all of 21 columns. This shows that the effects of Lasso regularization can be observed in Permutational Feature Importance plots of Logistic Regression models.</p>
<p>Despite all of the plots in this section are barplots, bars do not start in 0. We believe it is not a problem, because trend is more important than absolute values. Nevertheless, we would like to draw Reader’s attention to that fact.</p>
</div>
<div id="xgboost-and-random-forest-models" class="section level5">
<h5><span class="header-section-number">1.1.4.1.2</span> XGBoost and Random Forest models</h5>
<p>In Figure <a href="xai1-explainable-cards.html#fig:pfi-xgb-rf">1.18</a> we can observe that the most important column for both models is <code>Total_Trans_Amt</code> (sum of all transactions’ amount in last 12 months). This outcome can be logically explained: customers who do not use their credit card to execute many valuable transactions probably do not need that service, consequently resign. However, the drop-out loss for that column for the XGBoost is over 2 times higher than for the Random Forest, which means that the prior model bases its prediction on this column more than the latter model. Furthermore, more features are important for the XGBoost than for the Random Forest. We suppose this is a result of the models different training processes. New iterations (trees) in XGB are based on observations that were previously predicted incorrectly, thus new columns are taken into consideration to represent the differences between the observations. On the other hand, the Random Forest model selects the subset of the features randomly in each tree.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-xgb-rf"></span>
<img src="images/1-1-permutational-feature-xgb-rf.png" alt="Top 9 most important features in XGBoost (XGB) and Random Forest (RF) feature importance comparison. XGBoost has more important variables than Random Forest, but the importance of `Total_Trans_Amt` is over 2 times higher." width="700" />
<p class="caption">
FIGURE 1.18: Top 9 most important features in XGBoost (XGB) and Random Forest (RF) feature importance comparison. XGBoost has more important variables than Random Forest, but the importance of <code>Total_Trans_Amt</code> is over 2 times higher.
</p>
</div>
</div>
<div id="models-comparison" class="section level5">
<h5><span class="header-section-number">1.1.4.1.3</span> Models comparison</h5>
<p>We compared the Permutational Feature Importance of the group of Logistic Regression models, XGBoost model and Random Forest model. We can see in Figure <a href="xai1-explainable-cards.html#fig:pfi-all">1.19</a> the drop-out loss for <code>Total_Trans_Amt</code> in XGBoost is similar to drop-out in Logistic Regression models.</p>
<div class="figure" style="text-align: center"><span id="fig:pfi-all"></span>
<img src="images/1-1-pfi-all-models-4-vars.png" alt="Permutational Feature Impotance of 4 chosen variables for all models. Tree-based models generally have lower feature importance than Regression models. Effects of L1 regularization are neglectable in comparison to differences between models." width="800" />
<p class="caption">
FIGURE 1.19: Permutational Feature Impotance of 4 chosen variables for all models. Tree-based models generally have lower feature importance than Regression models. Effects of L1 regularization are neglectable in comparison to differences between models.
</p>
</div>
<p>If we compare the importance of <code>Total_Revolving_Bal</code> in Figure <a href="xai1-explainable-cards.html#fig:pfi-all">1.19</a>, we see a huge difference between tree based models and Regression models. The drop-out loss for the first ones is around 20 times lower than for the latter.</p>
<p>We can also examine some of the less important features such as <code>Gender</code> (see Figure <a href="xai1-explainable-cards.html#fig:pfi-all">1.19</a> ) and <code>Avg_Utilization_Ratio</code> (see Figure <a href="xai1-explainable-cards.html#fig:pfi-all">1.19</a>). In comparison to Regression models importance of these variables in XGBoost and Random Forest is neglectable. Therefore, we conclude that although the effects of L1 regularization in Logistic Regression are observable, tree-based models such as XGBoost and Random Forest select the most important features more restrictively.</p>
</div>
</div>
<div id="pdp-profiles" class="section level4">
<h4><span class="header-section-number">1.1.4.2</span> PDP profiles</h4>
<p>We created Partial Dependence Plots of all variables in the dataset for XGBoost, Random Forest and Logistic Regression with L1 models. Many of the plots turned out to be a horizontal line located on the level of the mean prediction of the models. An example of such a variable is shown in Figure <a href="xai1-explainable-cards.html#fig:pdp-chosen">1.20</a>, predictions of models does not change with the change of <code>Gender</code>. However, features that have high importance do have more complex plots. One can observe prediction varying with the change of <code>Total_Trans_Amt</code>, <code>Total_Revolving_Bal</code> or <code>Total_Ct_Chng_Q4_Q1</code>.</p>
<div class="figure" style="text-align: center"><span id="fig:pdp-chosen"></span>
<img src="images/1-1-pdp-chosen-vars.png" alt="Partial Dependence Plots of chosen features. Changing some variables does not affect the models' predictions (example of such a variable is `Gender`). There are 4 features (`Total_Trans_Amt`, `Total_Revolving_Bal`, `Total_Ct_Chng_Q4_Q1`, `Contacts_Count_12_mon`), which after beeing changed may influence the prediction." width="700" />
<p class="caption">
FIGURE 1.20: Partial Dependence Plots of chosen features. Changing some variables does not affect the models’ predictions (example of such a variable is <code>Gender</code>). There are 4 features (<code>Total_Trans_Amt</code>, <code>Total_Revolving_Bal</code>, <code>Total_Ct_Chng_Q4_Q1</code>, <code>Contacts_Count_12_mon</code>), which after beeing changed may influence the prediction.
</p>
</div>
<p>What we find interesting in Figure <a href="xai1-explainable-cards.html#fig:pdp-chosen">1.20</a> is an unobserved in PFI effect of the <code>Contacts_Count_12_mon</code> variable. The plot is steady for values 1-5 and raises rapidly when the feature takes the value of 6. We examined this case and figured out, that only approx. 0.58% of all observations have value 6 in <code>Contacts_Count_12_mon</code> column (see distribution of this variable in Figure <a href="xai1-explainable-cards.html#fig:distplots">1.21</a>). What is more, all of them describe attrited customers. We concluded there are two possible solutions:</p>
<ol style="list-style-type: decimal">
<li>The dataset is not balanced for this feature.</li>
<li>Indeed, the 6th contact with the bank representative is a breakthrough in the relationship with the customer.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:distplots"></span>
<img src="images/1-1-distribution-chosen-vars.png" alt="Having calculated PDP, it is useful to compare the results with variables distribution. " width="700" />
<p class="caption">
FIGURE 1.21: Having calculated PDP, it is useful to compare the results with variables distribution.
</p>
</div>
<p>We compared PDP and features distributions (see Figure <a href="xai1-explainable-cards.html#fig:distplots">1.21</a>). We can observe numerous attrited customers have <code>Total_Trans_Amt</code> between 2000 and 3000. It explains why there is an increase in prediction in this area of PDP plot for this variable.</p>
<p>Customers who did not churn have usually do not have <code>Total_Revolving_Bal</code> between 100 and 400. That is why prediction incresase for low values of <code>Total_Revolving_Bal</code>.</p>
</div>
<div id="ale-profiles" class="section level4">
<h4><span class="header-section-number">1.1.4.3</span> ALE profiles</h4>
<div class="figure" style="text-align: center"><span id="fig:ale-chosen"></span>
<img src="images/1-1-ale-chosen-vars.png" alt="Accumulated-local Profiles Plots of chosen features. ALE plots seem to be parallel to PDP plots. This may indicate additive models." width="700" />
<p class="caption">
FIGURE 1.22: Accumulated-local Profiles Plots of chosen features. ALE plots seem to be parallel to PDP plots. This may indicate additive models.
</p>
</div>
<p>Accumulated-local Profiles for XGBoost, Random Forest and Logistic Regression with L1 were calculated. The results for chosen variables are shown in Figure <a href="xai1-explainable-cards.html#fig:ale-chosen">1.22</a>. ALE plots seem to be very similar to PDP profiles. It may suggest there are no interactions between variables in the models. To examine that we plotted both PDP and ALE profiles in Figure <a href="xai1-explainable-cards.html#fig:ale-pdp-chosen-xgb">1.23</a>, Figure <a href="xai1-explainable-cards.html#fig:ale-pdp-chosen-rf">1.24</a>. We skip these plots for Logistic Regression because, by definition, there are no variables interactions in this class of models. ALE and PDP plots are parallel thus models detected no interactions between features and they can be additive.</p>
<div class="figure" style="text-align: center"><span id="fig:ale-pdp-chosen-xgb"></span>
<img src="images/1-1-ale-pdp-xgb.png" alt="Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for XGBoost. Parallel lines indicate that this model can be additive." width="700" />
<p class="caption">
FIGURE 1.23: Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for XGBoost. Parallel lines indicate that this model can be additive.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ale-pdp-chosen-rf"></span>
<img src="images/1-1-ale-pdp-rf.png" alt="Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for Random Forest. Parallel lines indicate that this model can be additive." width="700" />
<p class="caption">
FIGURE 1.24: Accumulated-local Profiles and Partial Dependence Profiles Plots of chosen features for Random Forest. Parallel lines indicate that this model can be additive.
</p>
</div>
</div>
</div>
<div id="summary" class="section level3">
<h3><span class="header-section-number">1.1.5</span> Summary</h3>
<p>In the article we analyzed the dataset and models trained on it. We explored the differences between the black-box, tree-based models and an explainable <em>Logistic Regression</em>. Various XAI methods were used for the comparison of the ML models. Local explanations showed that the misclassified observations are outliers. Therefore, the misclassification of those is not strange. Moreover, some of the observations are hard to classify by models, but a slight change of some of the predictors would make a prediction more confident. Global explanations of models gave us insight into how the models work. This lead to conclusions about the differences between those models. Firstly, tree-based models make their’s predictions on 5 or 6 values while a <em>Logistic Regression</em> (despite being modified with <em>L1</em> penalty) uses more predictors. Secondly, tree-based models were overfitted on some of the columns. Lastly, with <em>Logistic Regression</em> it is impossible to model more complicated relationship in data because this method assumes linearity.</p>

</div>
</div>
<!-- </div> -->
<h3> RashomonML</h3>
<div id="refs" class="references">
<div id="ref-dalex">
<p>Baniecki, Hubert, Wojciech Kretowicz, Piotr Piatyszek, Jakub Wisniewski, and Przemyslaw Biecek. 2020. “dalex: Responsible Machine Learning with Interactive Explainability and Fairness in Python.” <em>arXiv:2012.14406</em>. <a href="https://arxiv.org/abs/2012.14406">https://arxiv.org/abs/2012.14406</a>.</p>
</div>
<div id="ref-1-1-credit-card-dataset">
<p>Goyal, Sakshi. 2020. “Credit Card Customers.” <em>Kaggle</em>. <a href="https://www.kaggle.com/sakshigoyal7/credit-card-customers">https://www.kaggle.com/sakshigoyal7/credit-card-customers</a>.</p>
</div>
<div id="ref-1-1-white-box-black-box">
<p>Loyola-González, Octavio. 2019. “Black-Box Vs. White-Box: Understanding Their Advantages and Weaknesses from a Practical Point of View.” <em>IEEE Access</em> 7 (October): 154096–154113. <a href="https://doi.org/10.1109/ACCESS.2019.2949286">https://doi.org/10.1109/ACCESS.2019.2949286</a>.</p>
</div>
<div id="ref-1-1-l1-reg-random-forest">
<p>Saarela, Mirka, and Susanne Jauhiainen. 2021. “Comparison of Feature Importance Measures as Explanations for Classification Models.” <em>SN Applied Sciences</em> 3 (2). <a href="https://doi.org/10.1007/s42452-021-04148-9">https://doi.org/10.1007/s42452-021-04148-9</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="explainable-artificial-intelligence.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="explainable-artificial-inteligence-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mini-pw/2021L-WB-Book/edit/master/1-1-creditCards.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
